<head>
    <style>
      @import url(//fonts.googleapis.com/earlyaccess/jejumyeongjo.css);

      .jm-font{
          font-family: 'Jeju Myeongjo', serif;/*웹 폰트 지정*/
          color: black;
      }
      .b {
        background-color: #BBDEFB;
        padding: 10px 20px;
      }
    </style>
</head>

{% if page.title == "Home" %}

<h5 class="jm-font"> <b>머리말</b> </h5>
<p class="jm-font"> - 단기 프로젝트로 진행했던 기울어진 직사각형의 경계박스 예측과 오브젝트 트래킹에 대해 구현해 본 경험을 간략히 기술한다.</p>
<p class="jm-font"> - 프로젝트의 목적은 공장의 컨테이너에 제품이 지나갈 때, 제품의 라벨을 affine transform하여 바르게 펴주고, 또한 제품을 트래킹하여 실시간으로 갯수와 물체의 위치를 데이터화 
    하는 것이다. 이때 바르게 펴진 제품의 라벨은 OCR(문자인식)에 사용될 예정이다.</p>
<br></br>

<h5 class="jm-font"> <b>학습에 앞선 잡생각들</b> </h5>
<p class="jm-font"> - 학습에 앞서 기울어진 사각형을 포함하는 학습 데이터가 필요했다. OpenCV를 활용한 원하는 학습 데이터 수집 예시는 이전 글인 <a href="https://hyeongminmoon.github.io/U-2-Net_portrait_sketch">지난 스케치 포스팅</a>에서 자세히 다루고 있다. 
    본 프로젝트에서는 OpenCV의 Threshold와 Contour, SIFT, 해리스 코너 검출(Harris Corner), 허프변환(Hough) 등을 활용했다.</p>
<p class="jm-font"> - 사실 OpenCV를 잘만 활용하면 폴리곤 예측이 이미 가능하다는 생각이 들었다. 따라서 그럼에도 딥러닝을 적용해야하는 이유에 대해 고민해보았는데 그 이유는 포괄성 때문으로 결론지었다.
    전처리를 통한 폴리곤 예측은 새로운 라벨의 등장이나 다른 배경 등 변화에 대응하지 못한다. 딥러닝에 이러한 데이터를 어그맨테이션하여 학습시키게 되면 새로운 라벨이 들어와도 어느정도 포괄적으로
    동작할 수 있게된다. 이로써 'Bottom-Up 방식의 딥러닝 학습방법론'에대한 생각도 확고해졌다.</p>
<br></br>

<h5 class="jm-font"> <b>폴리곤 예측</b> </h5>
<p class="jm-font"> - 대부분 물체인식을 할 때 Bounding box label을 본 적이 있을 것이다. 다만 바운딩 박스를 사용하게 되면 기울어진 물체를 예측할 때 바운딩 박스내에 물체가 없는 공간이 생기게 된다.
    따라서 본 프로젝트처럼 affine transform 하려는 용도나, 물체의 부피를 예측하려는 용도로 ObjectDetection을 사용하기 위해선 Polygon Detect를 사용해야한다.</p>
<p class="jm-font"> - 폴리곤 예측에는 여러가지 방법이 있다. 다각형의 모든 꼭짓점의 위치를 예측하거나, Bounding box 예측처럼 xyxy 또는 xywh와 기울어진 각도를 측정하는 방법이 있다. 우선
    기울어진 사각형을 예측하기 위해 네 꼭짓점의 x,y좌표 즉 8개의 숫자를 예측하는 방법을 적용해보았다.</p>
<p class="jm-font"> - Pytorch의 여러가지 사전학습된 모델들을 평가하고
    쉽게 로드하여 사용할 수 있는 오픈소스인 <a href="https://github.com/rwightman/pytorch-image-models">Timm</a>를 활용하여 여러가지 모델의 마지막 레이어에 output이 8인 전결합층을
    쌓아 학습했다. 8개의 숫자만 예측하면 되니 간단할 것이라 생각했지만 결과는 그렇지 않았다. 대부분의 사전학습 모델은 분류모델로 학습되어 점의 위치를 예측하지는 못하는 모습이었다. 훗날 알게된 사실이지만
    분류모델은 커녕 Segmentation모델도 사실은 이미지의 위치정보를 제대로 학습하지 못한다는 사실을 알게되었다. 이에 대한 내용이 궁금하다면 CoordConv 논문을 살펴보기 바란다.</p>
<p class="jm-font"> - 따라서 다음 방법인 xywhΘ를 예측하는 방법을 적용해보았다. yolo기반으로 이를 구현한 깃허브 레파지토리들이 꽤 있다. 이중 나는 <a href="https://github.com/XinzeLee/PolygonObjectDetection">이 레파지토리</a>를 참고하였다.
    결과는 다음과 같다. 폴리곤 예측 결과와 affine transform 적용 결과이다.</p>
<p><img src="https://user-images.githubusercontent.com/32811724/149863108-60c4ceee-eb85-41c1-a927-e5e3c93c07e3.png" width="45%"></img></p>
<p><img src="https://user-images.githubusercontent.com/32811724/149863106-db2e0cb0-4c88-4e80-bc83-aacbc0e06f2b.png" width="45%"></img></p>
<br></br>

<h5 class="jm-font"> <b>오브젝트 트래킹</b> </h5>
<p class="jm-font"> - 그 이후에는 물체의 개수 및 위치 파악을 위해 오브젝트 트래킹을 시도했다. 오브젝트 트래킹은 이전에도 여러번 해보았는데, 
    Deepsort가 속도도 빠르고 성능도 우수해서 사실상 정설로 받아들이고 있다. 다른 사람도 마찬가지인지 deepsort + 모델 조합으로 구성된 레파지토리가 많으니 참고하길 바란다.</p>


<script src="https://utteranc.es/client.js"
        repo="HyeongminMoon/PolygonObjectDetection"
        issue-term="title"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>


<div class="row g-5 mb-5" style="text-align:left">
<hr width = "90%" color = "black">
<h5> 관련 포스팅 </h5>
      {% for item in site.data.publications.featured %}
        <p><a href="{{ item.url }}">{{ item.name }}</a></p>
      {% endfor %}
    {% else %}
      includes publications.html
      {% for item in site.data.publications.index %}
        <p><a href="{{ item.url }}">{{ item.name }}</a></p>
      {% endfor %}
    {% endif %}
</div>
